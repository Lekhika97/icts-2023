{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc65c96c-cdd6-4df8-a92c-6ca1aeb9a726",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170a8e9-c760-4ba0-ae31-b932a49beff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import uproot\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57d6a2-1a84-42fc-8246-6d3c38709ab9",
   "metadata": {},
   "source": [
    "# Generate toy data\n",
    "\n",
    "New Physics model 'NP1' is Gaussian (0,1), SM is Gaussian (0.5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895abc75-7e08-4a43-9eed-903b14256e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nEvents = 10**6\n",
    "gNP1 = (0,1)\n",
    "gSM = (0.5,1)\n",
    "\n",
    "X = np.concatenate([np.random.normal(loc=gNP1[0],scale=gNP1[1], size=nEvents//2), \n",
    "     np.random.normal(loc=gSM[0],scale=gSM[1], size=nEvents//2)])\n",
    "Y = np.concatenate([np.ones(nEvents//2), np.zeros(nEvents//2)])\n",
    "\n",
    "plt.hist(X[Y==0], bins=50, histtype=\"step\", range=(-4,5), label=\"SM\")\n",
    "plt.hist(X[Y==1], bins=50, histtype=\"step\", range=(-4,5), label=\"NP1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160b11f-f109-41fd-8d99-51a101db1227",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab14916-6c88-4edf-9af8-dd601b104101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.reshape(-1,1) ,Y, train_size=nEvents//2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c42cd-db69-41ee-ba39-fa82f0f876fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define likelihood ratio estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a24f56-adc7-49c0-b7ba-c77a5482bfce",
   "metadata": {},
   "source": [
    "$$LR = \\frac{P(data| NP_1)}{P(data| SM)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff29f8-a5aa-416c-8fa1-af1d164b37f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since the data is Gaussian, we know the analytical form of the likelihood ratio\n",
    "class trueLR:\n",
    "    def predict(self, X):\n",
    "        from scipy.stats import multivariate_normal\n",
    "        #Evaluate the probability density function at point X\n",
    "        rv_NP1 = multivariate_normal(??, ??).pdf\n",
    "        rv_SM = ??\n",
    "        LR = rv_NP1(X)/rv_SM(X)                                                        \n",
    "        return LR\n",
    "trueLR_model = trueLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f918f37-3cc4-42dc-8675-2c05e35bcd87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_SM_test = trueLR_model.predict(X=X_test[Y_test==0])\n",
    "LR_NP1_test = trueLR_model.predict(X=X_test[Y_test==1])\n",
    "\n",
    "plt.hist(LR_SM_test,\n",
    "         bins=100, histtype=\"step\", range=(0,10), label=\"LR SM Events\")\n",
    "plt.hist(LR_NP1_test,\n",
    "         bins=100, histtype=\"step\", range=(0,10), label=\"LR NP1 Events\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7752ba-c91d-4c9c-839f-4064398584d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Combined LR SM: \",LR_SM_test.prod(), \"Combined LR NP: \", LR_NP1_test.prod())\n",
    "print (\"Rreducing stats to only 100 events\")\n",
    "print (\"Combined LR back: \",LR_SM_test[:100].prod(), \"Combined LR signal: \", LR_NP1_test[:100].prod())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193d662-90f6-4736-85c8-a7b5c992cf81",
   "metadata": {},
   "source": [
    "# Assume you expect to observe only 10 events in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f53e3-11d3-4bc0-a228-bd3dfde30ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nData = 10\n",
    "nPseudoExp = 10**4\n",
    "dataset_LR_SM = LR_SM_test[:nPseudoExp*nData].reshape(nData,-1).prod(axis=0)\n",
    "dataset_LR_NP1 = LR_NP1_test[:nPseudoExp*nData].reshape(nData,-1).prod(axis=0)\n",
    "\n",
    "plt.hist(dataset_LR_SM,\n",
    "         bins=100, histtype=\"step\", range=(0,10), label=\"True LR: pseudo-experiments with SM\")\n",
    "plt.hist(dataset_LR_NP1,\n",
    "         bins=100, histtype=\"step\", range=(0,10), label=\"True LR: pseudo-experiments with NP1\")\n",
    "threshold = 1.35\n",
    "plt.axvline(x = threshold, color = 'r', label = 'Threshold to reject SM')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb985769-7a9a-4702-9c09-51647880cb74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(dataset_LR_SM > threshold).sum() / dataset_LR_SM.shape[0], (dataset_LR_NP1 > threshold).sum() / dataset_LR_NP1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a118875a-4982-43e8-8022-82118ad3cbff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to get this in a \"Likelihood-Free\" way ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e0994-d2fa-46fe-a1ce-876f74456160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "D = Dense(256, activation=\"relu\")(inputs) # first layer\n",
    "D = Dense(256, activation=\"relu\")(D) \n",
    "D = Dense(1, activation=\"sigmoid\")(D) # last layer\n",
    "clf = Model(inputs=inputs, outputs=D)\n",
    "\n",
    "clf.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf58fc-c1df-40ef-bf88-ca91d7b520f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit(x=X_train, y=Y_train, epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d4bbe16-c36b-404f-86a0-95a6ff1f029d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overtrained classifier example\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "D = Dense(256, activation=\"linear\")(inputs) # first layer\n",
    "D = Dense(256, activation=\"linear\")(D) \n",
    "D = Dense(1, activation=\"sigmoid\")(D) # last layer\n",
    "clf = Model(inputs=inputs, outputs=D)\n",
    "\n",
    "clf.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "nTrainSmall = 10**3\n",
    "clf.fit(x=X_train[:nTrainSmall], y=Y_train[:nTrainSmall],\n",
    "        epochs=10, batch_size=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2e8819-952c-44ce-bf14-b070576fdde0",
   "metadata": {},
   "source": [
    "$$ LR = \\frac{s}{1-s} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0388abc-e586-43db-8fb0-7172dd88ced0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaeddad-411e-4022-8ab5-9de57230028a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80f30c-d748-4e09-8a68-7000b196c9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_pred_SM_test = lr_pred[Y_test==0]\n",
    "LR_pred_NP1_test = lr_pred[Y_test==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45dd5c3-7537-490a-9710-a7be878c2f9b",
   "metadata": {},
   "source": [
    "Let's see how close the estimated LRs are to the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da5d5f-1814-478a-b366-b9fec8b31d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"SM data\")\n",
    "print (\"True LR: \", LR_SM_test[:5], \"\\nPred LR: \", LR_pred_SM_test[:5])\n",
    "print(\"NP1 data\")\n",
    "print (\"True LR: \", LR_NP1_test[:5], \"\\nPred LR: \", LR_pred_NP1_test[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d314490-c776-4c56-a6a7-c6fbd72def8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Uses: \n",
    "- **Hypothesis testing**\n",
    "- Negative weighted events: reweight MC with negative weights into MC with only positive weights\n",
    "- Re-weighing Pythia to Herwig etc\n",
    "- Unfolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb91bea-5b21-4375-9b5f-203f1edc0bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same as before, but now the estimated LR coems from the classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2234c-0453-4c59-8531-ad80a8f1ae5b",
   "metadata": {},
   "source": [
    "But is this estimate good enough? Is it accurate everywhere? \n",
    "What if we have a bias in some phase space? \n",
    "\n",
    "Need to visualise the LR leant, so flip the classifier into a 'generative model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617cdfba-67df-47e1-a408-dac316c471b4",
   "metadata": {},
   "source": [
    "## Diagnostics: Re-weighting SM events to look like NP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b2ee6-dc16-45bd-a23a-aec661fb9445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = lr_pred\n",
    "\n",
    "plt.hist(X_test[Y_test==0], bins=50, histtype=\"step\", density=1, range=(-4,5), label=\"SM\")\n",
    "plt.hist(X_test[Y_test==1], bins=50, histtype=\"step\", density=1, range=(-4,5), label=\"NP1\")\n",
    "plt.hist(X_test[Y_test==0], weights=weights[Y_test==0], bins=50, histtype=\"step\", density=1, range=(-4,5), label=\"Reweight SM -> NP1\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Observable 1\")\n",
    "plt.ylabel(\"Arbitrary units\")\n",
    "plt.title(\"Diagnostics with reweighting\")\n",
    "#plt.savefig(\"reweight.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe2c93-07cf-4273-ab0b-f26bf94ea4d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Diagnostics: Calibration curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4920173-03b7-40ba-8e2e-9d9f3ef94f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on training set\n",
    "y_pred_train = clf.predict(X_train, batch_size=4*1024).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c057218-d636-46c5-bec1-46c6c77827b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from extra_functions import compare_train_test\n",
    "\n",
    "compare_train_test(\n",
    "    y_pred_train,\n",
    "    Y_train,\n",
    "    y_pred,\n",
    "    Y_test,\n",
    "    xlabel=\"Classifier Score\",\n",
    "    title=\"Score Distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1489ff-0c06-4c65-9244-44dd51e846c7",
   "metadata": {},
   "source": [
    "### Now for calibration curve, we scan over different thresholds and plot the purity. \n",
    "Purity of NP1 events for a given threshold cut is nNP1/(nNP1+nSM) that pass the cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18422fab-9962-479f-84bf-dd9f5a86274f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(Y_test, y_pred, n_bins=50)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='ideal')\n",
    "plt.plot(prob_true, prob_pred, marker='.', label='clf test')\n",
    "# prob_true, prob_pred = calibration_curve(Y_train, y_pred_train, n_bins=50)\n",
    "# plt.plot(prob_true, prob_pred, marker='.', label='clf train')\n",
    "plt.legend()\n",
    "plt.title(\"Calibration curve\")\n",
    "plt.xlabel(\"True purity\")\n",
    "plt.ylabel(\"Predicted purity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad0a96-ce2d-45bd-8412-401967c8013a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise:\n",
    "- Try plots with a poorly trained classifier\n",
    "\n",
    "## Optional:\n",
    "- Try 2D Gaussian models for SM and NP1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55f205-85cc-4481-9550-3145d6102db8",
   "metadata": {},
   "source": [
    "# Now on physics dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530f7b5-032b-486c-945e-d7b6d34f9c50",
   "metadata": {},
   "source": [
    "We will assume that B is H_0 and S is H_1 (even though actually H1 as S+B makes more sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e15f0-8ea2-477b-861d-1fe92d31d1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# same data & data loading code as S vs B tutorial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "filename = \"dataFiles/dataWW_d1.root\"\n",
    "file = uproot.open(filename)\n",
    "\n",
    "# show what is inside the root file loaded from uproot\n",
    "print(file.classnames())\n",
    "print(file.keys())\n",
    "\n",
    "tree = file[\"tree_event\"]  # select the TTree inside the root file\n",
    "dfall = tree.arrays(library=\"pd\")  # convert uproot TTree into pandas dataframe\n",
    "\n",
    "label_weights = (dfall[dfall.label == 0].mcWeight.sum(), dfall[dfall.label == 1].mcWeight.sum())\n",
    "fulldata = dfall[\n",
    "    #(dfall.lep_n == 2) & (dfall.mcWeight > 0)\n",
    "    (dfall.lep_n == 2)\n",
    "]  # only keep events with exactly two leptons\n",
    "\n",
    "target = fulldata[\"label\"]\n",
    "weights = fulldata[\"mcWeight\"]\n",
    "\n",
    "#true_class_weights = [weights[target == 0].sum(), weights[target == 1].sum()]\n",
    "\n",
    "featureList = ['met_et', 'met_phi', 'lep_n',\n",
    "       'lep_pt_0', 'lep_pt_1', 'lep_eta_0', 'lep_eta_1', 'lep_phi_0',\n",
    "       'lep_phi_1', 'lep_E_0', 'lep_E_1', 'lep_charge_0', 'lep_charge_1',\n",
    "       'lep_type_0', 'lep_type_1', 'jet_n', 'jet_pt_0', 'jet_pt_1',\n",
    "       'jet_eta_0', 'jet_eta_1', 'jet_phi_0', 'jet_phi_1', 'jet_E_0',\n",
    "       'jet_E_1']\n",
    "data = pd.DataFrame(fulldata, columns=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e38851-6600-42a6-8d3f-0cdd87483269",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.75  # fraction of sample used for training\n",
    "\n",
    "XP_train, XP_test, yP_train, yP_test, weightsP_train, weightsP_test = train_test_split(\n",
    "    data, target, weights, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369d611-3c7a-4712-9a11-1a4d730ea68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prec = 2\n",
    "\n",
    "scalerP = StandardScaler()\n",
    "XP_train = scalerP.fit_transform(XP_train)\n",
    "XP_test = scalerP.transform(XP_test)\n",
    "\n",
    "class_weights_train = (weightsP_train[yP_train == 0].sum(), weightsP_train[yP_train == 1].sum())\n",
    "\n",
    "for i in range(len(class_weights_train)):\n",
    "    weightsP_train[yP_train == i] *= (\n",
    "        max(class_weights_train) / class_weights_train[i]\n",
    "    )  # equalize number of background and signal event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111cdb6-00a8-43db-95b0-bd207ecf5bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(XP_train.shape[1],))\n",
    "C = Dense(1024, activation=\"relu\")(inputs) # first layer\n",
    "C = Dense(1024, activation=\"relu\")(C) \n",
    "C = Dense(1, activation=\"sigmoid\")(C) # last layer\n",
    "model = Model(inputs=inputs, outputs=C)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb2b6a-ae8a-46f8-975e-a965bc8fac00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x=XP_train, y=yP_train, epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b7f9b-93f2-43e5-bd16-023bc38f24fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yP_pred = model.predict(XP_test, batch_size=4*1024).ravel()\n",
    "yP_train_pred = model.predict(XP_train, batch_size=4*1024).ravel()\n",
    "lrP_pred = yP_pred/(1-yP_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca16ed-74e3-460f-b973-919e58c28ec3",
   "metadata": {},
   "source": [
    "## Typical plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c281f-925b-4a2b-9ec3-4a3a5cfbc593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# easier to remove negative weighted events for fast AUC calucaltion\n",
    "posWeightsTrain, posWeightsTest = weightsP_train>0, weightsP_test>0\n",
    "\n",
    "fpr_test, tpr_test, _ = roc_curve(y_true=yP_test[posWeightsTest],\n",
    "                                  y_score=yP_pred[posWeightsTest], \n",
    "                                  sample_weight=weightsP_test[posWeightsTest])\n",
    "fpr_train, tpr_train, _ = roc_curve(y_true=yP_train[posWeightsTrain],\n",
    "                                    y_score=yP_train_pred[posWeightsTrain], \n",
    "                                    sample_weight=weightsP_train[posWeightsTrain])\n",
    "auc_test = roc_auc_score(y_true=yP_test[posWeightsTest], \n",
    "                         y_score=yP_pred[posWeightsTest],\n",
    "                         sample_weight=weightsP_test[posWeightsTest])\n",
    "auc_train = roc_auc_score(y_true=yP_train[posWeightsTrain],\n",
    "                          y_score=yP_train_pred[posWeightsTrain],\n",
    "                          sample_weight=weightsP_train[posWeightsTrain])\n",
    "plt.plot(fpr_test, tpr_test, color='tab:blue', lw=2, ls=\"--\", label=f\"Test set auc: {auc_test:.4f}\")\n",
    "plt.plot(fpr_train, tpr_train, color='tab:orange', lw=2, ls=\":\", label=f\"Training set auc: {auc_train:.4f}\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e590fba-c70b-473c-85b2-4085d122f86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from extra_functions import compare_train_test\n",
    "\n",
    "compare_train_test(\n",
    "    yP_train_pred,\n",
    "    yP_train,\n",
    "    yP_pred,\n",
    "    yP_test,\n",
    "    xlabel=\"NN Score\",\n",
    "    title=\"Score distribution\",\n",
    "    weights_train=weightsP_train.values,\n",
    "    weights_test=weightsP_test.values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd0148-4876-45e3-b4ea-15e894eafa98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Advanced Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d010d13-2d91-474c-b7d7-c64aae3e80b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reweights = weightsP_test * lrP_pred\n",
    "f = 3; rangee = (-2,10)  # which observable to plot, what range\n",
    "plt.hist(XP_test[yP_test==0, f], weights=weightsP_test[yP_test==0], \n",
    "         bins=50, range=rangee, histtype=\"step\", density=1, label=\"B\")\n",
    "plt.hist(XP_test[yP_test==1, f], weights=weightsP_test[yP_test==1], \n",
    "         bins=50, range=rangee, histtype=\"step\", density=1, label=\"S\")\n",
    "plt.hist(XP_test[yP_test==0, f], weights=reweights[yP_test==0], \n",
    "         bins=50, range=rangee, histtype=\"step\", density=1, label=\"Reweight B -> S\")\n",
    "plt.xlabel(featureList[f])\n",
    "plt.ylabel(\"Arbitrary units\")\n",
    "plt.title(\"Diagnostics with reweighting\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# try plotting f=4, how would you improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7cdea-0cee-4e93-9d50-46ea58efc0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(yP_test, yP_pred, n_bins=50)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='ideal')\n",
    "plt.plot(prob_true, prob_pred, marker='.', label='clf test')\n",
    "prob_true, prob_pred = calibration_curve(yP_train, yP_train_pred, n_bins=50)\n",
    "plt.plot(prob_true, prob_pred, marker='.', label='clf train')\n",
    "plt.legend()\n",
    "plt.xlabel(\"True purity\")\n",
    "plt.ylabel(\"Predicted purity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3cce7-cbf1-4b04-a9f9-028172369c8b",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "- How can we improve the performance? Preprocessing & HPO, regularization (dropouts), early-stopping\n",
    "- Ensembling\n",
    "\n",
    "## Optional:\n",
    "- Investigate phase space with poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdebd396-a31f-4e27-9ec9-7cd6f6088632",
   "metadata": {},
   "source": [
    "# Omnifold: Multi-dimensional unbinned unfolding\n",
    "Content borrowed from Vinicius Mikuni (https://github.com/usatlas-ml-training/lbnl-2023/blob/main/unfolding/DIS_Omnifold-sol.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745d1b8-4c1d-4488-b8fa-3bb93b1af060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import omnifold as of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0874f4-d493-40b0-9fc7-1d03638f5652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_Events = 10**5\n",
    "\n",
    "# Synthetic\n",
    "theta0_G = np.random.normal(0.2, 0.8, N_Events)  # Generator-level synthetic sample\n",
    "theta0_S = np.array([(x + np.random.normal(0, 0.5)) for x in theta0_G])  # Detector smearing for synthetic sample\n",
    "\n",
    "theta0 = np.stack([theta0_G, theta0_S], axis=1)\n",
    "\n",
    "# Natural\n",
    "theta_unknown_G = np.random.normal(0, 1, N_Events)\n",
    "theta_unknown_S = np.array([(x + np.random.normal(0, 0.5)) for x in theta_unknown_G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b060e-08ef-4bb6-9203-f485b2e1d361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, _ = plt.hist(theta0_G, bins=np.linspace(-3, 3, 20), color='blue', alpha=0.5, label=\"MC, true\")\n",
    "_, _, _ = plt.hist(theta0_S, bins=np.linspace(-3, 3, 20), histtype=\"step\", color='black', ls=':', label=\"MC, reco\")\n",
    "_, _, _ = plt.hist(theta_unknown_G, bins=np.linspace(-3, 3, 20), color='orange', alpha=0.5, label=\"Data, true\")\n",
    "_, _, _ = plt.hist(theta_unknown_S, bins=np.linspace(-3, 3, 20), histtype=\"step\", color='black', label=\"Data, reco\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"events\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edb9ab-f2fd-411e-a9ba-dd2a0f42266c",
   "metadata": {},
   "source": [
    "### Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21862b91-8165-4f01-859e-90e2a3904b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = Input((1,))\n",
    "hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "outputs = Dense(1, activation='sigmoid')(hidden_layer_3)\n",
    "model_gaus = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8da10-6a9f-494a-ad7b-de5eb9eb1334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_Iterations = 2\n",
    "myweights = of.omnifold(theta0_G, theta0_S, theta_unknown_S, N_Iterations, model_gaus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432dc8e-2e36-4461-ba83-0ec7c18494d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot unfolded distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319f0c1-8dfb-4746-a361-29cd5bd70281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, _ = plt.hist(theta0_G, bins=np.linspace(-3, 3, 20), color='blue', alpha=0.5, label=\"MC, true\")\n",
    "_, _, _ = plt.hist(theta_unknown_G, bins=np.linspace(-3, 3, 20), color='orange', alpha=0.5, label=\"Data, true\")\n",
    "_, _, _ = plt.hist(\n",
    "    theta0_G,\n",
    "    weights=myweights[-1, 1, :],\n",
    "    bins=np.linspace(-3, 3, 20),\n",
    "    color='black',\n",
    "    histtype=\"step\",\n",
    "    label=\"OmniFolded\",\n",
    "    lw=2,\n",
    ")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"events\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd03bb-fb71-4f18-a641-237b04539c1d",
   "metadata": {},
   "source": [
    "### Plot the distribution at reco level instead of gen level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ce327-7ee9-4d85-abe4-79b12e333e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_,_,_=plt.hist(theta0_S,bins=np.linspace(-3,3,20),color='blue',alpha=0.5,label=\"MC, reco\")\n",
    "_,_,_=plt.hist(theta_unknown_S,bins=np.linspace(-3,3,20),color='orange',alpha=0.5,label=\"Data, reco\")\n",
    "_,_,_=plt.hist(theta0_S,weights=myweights[-1, 1, :], bins=np.linspace(-3,3,20),color='black',histtype=\"step\",label=\"OmniFolded\",lw=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"events\")\n",
    "plt.legend(frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
